from pathlib import Path
import threading

import requests
from rich.console import Console
from rich.panel import Panel
from rich.prompt import Confirm, Prompt
from rich.table import Table
from rich.live import Live
from rich.spinner import Spinner
from rich.layout import Layout
from rich.text import Text
from rich.columns import Columns
from rich.align import Align
import time
import subprocess

def select_from_menu(
    console: Console,
    options: list[str],
    title: str,
    default_index: int = 0
) -> str | None:
    """
    Ags:
        options: ì„ íƒ ê°€ëŠ¥í•œ ì˜µì…˜ë“¤
        title: ë©”ë‰´ ì œëª©
        show_numbers: ë²ˆí˜¸ í‘œì‹œ ì—¬ë¶€
        default_index: ê¸°ë³¸ ì„ íƒ ì¸ë±ìŠ¤
    Returns:
        ì„ íƒëœ ì˜µì…˜ ì¸ë±ìŠ¤, ì·¨ì†Œì‹œ None
    """

    if not options:
        return None

    # ë°ì€ ë³´ë¼ìƒ‰ì„ ìœ„ì£¼ë¡œ í•œ ìŠ¤íƒ€ì¼ë§
    header_panel = Panel(
        f"[bold bright_magenta]{title}[/bold bright_magenta]",
        border_style="magenta",
        padding=(1, 2)
    )
    console.print(header_panel)

    table = Table(
        box=None,
        padding=(0, 2),
        border_style="bright_magenta",
        header_style="bold bright_magenta"
    )
    table.add_column("ë²ˆí˜¸", style="bright_cyan", width=6, justify="center")
    table.add_column("ì˜µì…˜", style="bright_white")

    for i, option in enumerate(options, 1):
        # ê¸°ë³¸ ì„ íƒ í•­ëª©ì„ ë” ëˆˆì— ë„ê²Œ í‘œì‹œ
        if i == default_index + 1:
            style = "bold bright_magenta on grey23"
            indicator = "â†’ "
        else:
            style = "bright_white"
            indicator = "  "

        table.add_row(
            f"[bright_cyan]{i}[/bright_cyan]",
            f"[{style}]{indicator}{option}[/{style}]"
        )

    console.print(table)

    # ì„ íƒì§€ ìƒì„±
    choices = [str(i) for i in range(1, len(options) + 1)]
    choices.append("q")

    choice_panel = Panel(
        "[bright_magenta]ë²ˆí˜¸ë¥¼ ì„ íƒí•˜ì„¸ìš”[/bright_magenta] [dim](q: ì·¨ì†Œ)[/dim]",
        border_style="bright_magenta",
        padding=(0, 1)
    )
    console.print(choice_panel)

    choice = Prompt.ask(
        "[bright_magenta]ì„ íƒ",
        choices=choices,
        default=str(default_index + 1)
    )

    if choice == "q":
        return None

    return options[int(choice) - 1]


class OllamaSetup:
    def __init__(self, console: Console):
        self.console = console
        self.settings_path = Path.cwd() / ".ocli" / "settings.json"
        self.api_url = "http://localhost:11434/api"

    def check_ollama_installation(self) -> bool:
        try:
            result = subprocess.run(
                ["ollama", "--version"],
                capture_output=True,
                text=True,
                timeout=5
            )
            return result.returncode == 0
        except (subprocess.SubprocessError, FileNotFoundError):
            return False

    def check_ollama_service(self) -> bool:
        status_panel = Panel(
            "[bold bright_magenta]ğŸ” Ollama ì„œë¹„ìŠ¤ ìƒíƒœë¥¼ í™•ì¸í•©ë‹ˆë‹¤...[/bold bright_magenta]",
            border_style="magenta",
            padding=(1, 2)
        )
        self.console.print(status_panel)

        try:
            response = requests.get("http://localhost:11434/api/version", timeout=3)
            return response.status_code == 200
        except requests.RequestException:
            return False

    def get_available_ollama_models(self) -> list[str]:
        try:
            result = subprocess.run(
                ["ollama", "list"],
                capture_output=True,
                text=True,
                timeout=10
            )

            if result.returncode != 0:
                return []

            models = []
            lines = result.stdout.strip().split('\n')[1:]  # í—¤ë” ì œì™¸
            for line in lines:
                if line.strip():
                    model_name = line.split()[0]
                    models.append(model_name)

            return models
        except (subprocess.SubprocessError, FileNotFoundError):
            return []

    def show_install_recommend_ollama_model(self):
        recommended_models = [
            ('gpt-oss:20b', 'OpenAIâ€™s open-weight models designed for powerful reasoning, agentic tasks, and versatile developer use cases. (14GB)', ),
            ('deepseek-r1:8b', 'DeepSeek-R1 is a family of open reasoning models with performance approaching that of leading models, such as O3 and Gemini 2.5 Pro. (5.2GB)'),
            ('gemma3:4b', 'The current, most capable model that runs on a single GPU. (3.3GB)')
        ]

        self.console.print("\n[bright_magenta]ğŸ“¦ ê¶Œì¥ Ollama ëª¨ë¸:[/bright_magenta]")

        table = Table(border_style="bright_magenta", header_style="bold bright_magenta")
        table.add_column('ë²ˆí˜¸', style='bright_cyan', justify='center', width=6)
        table.add_column('ëª¨ë¸ëª…', style='bright_magenta')
        table.add_column('ì„¤ëª…', style='bright_white')

        for i, (model, description) in enumerate(recommended_models, 1):
            table.add_row(str(i), model, description)

        self.console.print(table)

        choice = Prompt.ask(
            "[bright_magenta]ì„¤ì¹˜í•  ëª¨ë¸ ë²ˆí˜¸ë¥¼ ì„ íƒí•˜ì„¸ìš” (1-3, ë˜ëŠ” 's'ë¡œ ê±´ë„ˆë›°ê¸°)[/bright_magenta]",
            choices=["1", "2", "3", "s"],
            default="1"
        )

        if choice == 's':
            self.console.print(Panel(
                "[yellow]ëª¨ë¸ ì„¤ì¹˜ë¥¼ ê±´ë„ˆëœë‹ˆë‹¤.[/yellow]",
                border_style="yellow",
                padding=(0, 1)
            ))
            return False

        model_to_install = recommended_models[int(choice) - 1][0]

        download_panel = Panel(
            f"[bright_magenta]ğŸ“¥ {model_to_install} ëª¨ë¸ì„ ë‹¤ìš´ë¡œë“œ ì¤‘...[/bright_magenta]\n[dim]ì´ ì‘ì—…ì€ ëª‡ ë¶„ì´ ê±¸ë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤.[/dim]",
            border_style="magenta",
            padding=(1, 2)
        )
        self.console.print(download_panel)

        try:
            # ollama pull ëª…ë ¹ì–´ ì‹¤í–‰
            process = subprocess.Popen(
                ["ollama", "pull", model_to_install],
                stdout=subprocess.PIPE,
                stderr=subprocess.PIPE,
                text=True
            )

            # ì‹¤ì‹œê°„ ì¶œë ¥
            if process.stdout is not None:
                for line in process.stdout:
                    self.console.print(f"  [bright_cyan]â–¶[/bright_cyan] {line.strip()}")

            process.wait()

            if process.returncode == 0:
                success_panel = Panel(
                    f"[bold green]âœ“ {model_to_install} ëª¨ë¸ì´ ì„±ê³µì ìœ¼ë¡œ ì„¤ì¹˜ë˜ì—ˆìŠµë‹ˆë‹¤![/bold green]",
                    border_style="green",
                    padding=(1, 2)
                )
                self.console.print(success_panel)
                return True
            else:
                error_panel = Panel(
                    "[red]âŒ ëª¨ë¸ ì„¤ì¹˜ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.[/red]",
                    border_style="red",
                    padding=(1, 2)
                )
                self.console.print(error_panel)
                return False

        except subprocess.SubprocessError as e:
            error_panel = Panel(
                f"[red]âŒ ëª¨ë¸ ì„¤ì¹˜ ì‹¤íŒ¨: {e}[/red]",
                border_style="red",
                padding=(1, 2)
            )
            self.console.print(error_panel)
            return False

    def show_ollama_installation_guide(self):
        error_panel = Panel(
            "[red]âŒ Ollamaê°€ ì„¤ì¹˜ë˜ì–´ ìˆì§€ ì•ŠìŠµë‹ˆë‹¤.[/red]",
            border_style="red",
            padding=(1, 2)
        )
        self.console.print(error_panel)

        """Ollama ì„¤ì¹˜ ê°€ì´ë“œ í‘œì‹œ"""
        guide = """
[bold bright_magenta]Ollama ì„¤ì¹˜ ë°©ë²•:[/bold bright_magenta]

[bright_cyan]macOS:[/bright_cyan]
curl -fsSL https://ollama.com/install.sh | sh

[bright_cyan]Linux:[/bright_cyan]
curl -fsSL https://ollama.com/install.sh | sh

[bright_cyan]Windows:[/bright_cyan]
https://ollama.com/download/windows ì—ì„œ ë‹¤ìš´ë¡œë“œ

ì„¤ì¹˜ í›„ í„°ë¯¸ë„ì—ì„œ 'ollama serve'ë¥¼ ì‹¤í–‰í•˜ì—¬ ì„œë¹„ìŠ¤ë¥¼ ì‹œì‘í•˜ì„¸ìš”.
        """

        panel = Panel(
            guide,
            title="ğŸ¦™ Ollama ì„¤ì¹˜ ê°€ì´ë“œ",
            border_style="magenta"
        )
        self.console.print(panel)

    def run_model(self, model: str):
        run_panel = Panel(
            f"[bold bright_magenta]ğŸ¤– {model} ëª¨ë¸ì„ ì‹¤í–‰í•©ë‹ˆë‹¤...[/bold bright_magenta]",
            border_style="magenta",
            padding=(1, 2)
        )
        self.console.print(run_panel)

        try:
            subprocess.run(["ollama", "run", model], check=True)
            success_panel = Panel(
                f"[green]âœ“ {model} ëª¨ë¸ì´ ì„±ê³µì ìœ¼ë¡œ ì‹¤í–‰ë˜ì—ˆìŠµë‹ˆë‹¤.[/green]",
                border_style="green",
                padding=(1, 2)
            )
            self.console.print(success_panel)
        except subprocess.CalledProcessError:
            error_panel = Panel(
                f"[red]âŒ {model} ëª¨ë¸ ì‹¤í–‰ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.[/red]",
                border_style="red",
                padding=(1, 2)
            )
            self.console.print(error_panel)

    def run_ollama_serve(self) -> bool:
        start_panel = Panel(
            "[bright_magenta]ğŸš€ Ollama ì„œë¹„ìŠ¤ë¥¼ ì‹œì‘í•©ë‹ˆë‹¤...[/bright_magenta]",
            border_style="magenta",
            padding=(1, 2)
        )
        self.console.print(start_panel)

        subprocess.Popen(
            ['ollama', 'serve'],
            stdout=subprocess.DEVNULL,
            stderr=subprocess.DEVNULL,
            start_new_session=True
        )

        for i in range(10):
            time.sleep(1)
            if self.check_ollama_service():
                return True

        return False

    def load_model(self, model_name: str) -> bool:
        """ëª¨ë¸ ë¡œë“œ ì‹œ ì‹¤ì‹œê°„ íƒ€ì´ë¨¸ì™€ í•¨ê»˜ ì§„í–‰ ìƒí™© í‘œì‹œ"""
        start_time = time.time()
        is_loading = True

        def loading_timer():
            """ë°±ê·¸ë¼ìš´ë“œì—ì„œ ì‹¤í–‰ë  íƒ€ì´ë¨¸ í•¨ìˆ˜"""
            while is_loading:
                elapsed = time.time() - start_time
                return f"[bright_cyan]{elapsed:.1f}ì´ˆ[/bright_cyan]"

        # Layout êµ¬ì„±
        layout = Layout()
        layout.split_column(
            Layout(name="header", size=3),
            Layout(name="main", size=5)
        )

        # í—¤ë” êµ¬ì„±
        header_text = Panel(
            f"[bold bright_magenta]ğŸ”„ {model_name} ëª¨ë¸ì„ ë¡œë“œí•©ë‹ˆë‹¤...[/bold bright_magenta]",
            border_style="magenta",
            padding=(0, 2)
        )

        # ë©”ì¸ ì˜ì—­ êµ¬ì„± (ìŠ¤í”¼ë„ˆ + íƒ€ì´ë¨¸)
        def create_main_content():
            elapsed = time.time() - start_time
            spinner_text = Text()
            spinner_text.append("ë¡œë”© ì¤‘", style="bright_magenta")
            spinner_text.append(" â€¢ ", style="dim")
            spinner_text.append(f"{elapsed:.1f}ì´ˆ", style="bright_cyan")

            return Panel(
                Align.center(
                    Columns([
                        Spinner("dots", text=spinner_text, style="bright_magenta"),
                        Text(f"[bright_cyan]ì†Œìš” ì‹œê°„: {elapsed:.1f}ì´ˆ[/bright_cyan]")
                    ], align="center")
                ),
                border_style="magenta",
                padding=(1, 2)
            )

        # Live ë””ìŠ¤í”Œë ˆì´ë¡œ ì‹¤ì‹œê°„ ì—…ë°ì´íŠ¸
        with Live(layout, refresh_per_second=10, console=self.console, auto_refresh=True) as live:
            layout["header"].update(header_text)

            def update_display():
                while is_loading:
                    layout["main"].update(create_main_content())
                    time.sleep(0.1)

            # ì—…ë°ì´íŠ¸ ìŠ¤ë ˆë“œ ì‹œì‘
            update_thread = threading.Thread(target=update_display, daemon=True)
            update_thread.start()

            try:
                response = requests.post(
                    f"{self.api_url}/generate",
                    json={
                        "model": model_name,
                        "prompt": "Hello",
                        "stream": False
                    },
                    timeout=60
                )

                is_loading = False
                elapsed_time = time.time() - start_time

                if response.status_code == 200:
                    success_panel = Panel(
                        f"[bold green]âœ“ {model_name} ëª¨ë¸ì´ ì„±ê³µì ìœ¼ë¡œ ë¡œë“œë˜ì—ˆìŠµë‹ˆë‹¤![/bold green]\n[dim]ì†Œìš” ì‹œê°„: {elapsed_time:.1f}ì´ˆ[/dim]",
                        border_style="green",
                        padding=(1, 2)
                    )
                    live.update(success_panel)
                    time.sleep(2)  # ê²°ê³¼ë¥¼ ì ì‹œ ë³´ì—¬ì¤Œ
                    return True
                else:
                    error_panel = Panel(
                        f"[red]âŒ {model_name} ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {response.status_code}[/red]\n[dim]ì†Œìš” ì‹œê°„: {elapsed_time:.1f}ì´ˆ[/dim]",
                        border_style="red",
                        padding=(1, 2)
                    )
                    live.update(error_panel)
                    time.sleep(2)
                    return False

            except Exception as e:
                is_loading = False
                elapsed_time = time.time() - start_time
                error_panel = Panel(
                    f"[red]âŒ ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {e}[/red]\n[dim]ì†Œìš” ì‹œê°„: {elapsed_time:.1f}ì´ˆ[/dim]",
                    border_style="red",
                    padding=(1, 2)
                )
                live.update(error_panel)
                time.sleep(2)
                return False

    def setup_ai_providers(self):
        """AI Provider ì„¤ì • í”„ë¡œì„¸ìŠ¤ ì‹¤í–‰"""
        setup_panel = Panel(
            "[bold bright_magenta]ğŸ¤– Ollama ì„¤ì •ì„ ì‹œì‘í•©ë‹ˆë‹¤...[/bold bright_magenta]",
            border_style="magenta",
            padding=(1, 2)
        )
        self.console.print(setup_panel)

        # 1. Ollama í™•ì¸
        ollama_installed: bool = self.check_ollama_installation()
        if not ollama_installed:
            error_panel = Panel(
                "[red]âŒ Ollamaê°€ ì„¤ì¹˜ë˜ì–´ ìˆì§€ ì•ŠìŠµë‹ˆë‹¤.[/red]",
                border_style="red",
                padding=(1, 2)
            )
            self.console.print(error_panel)
            self.show_ollama_installation_guide()
            return False

        success_panel = Panel(
            "[green]âœ“ Ollamaê°€ ì„¤ì¹˜ë˜ì–´ ìˆìŠµë‹ˆë‹¤.[/green]",
            border_style="green",
            padding=(0, 1)
        )
        self.console.print(success_panel)

        ollama_running = self.check_ollama_service()

        if not ollama_running:
            warning_panel = Panel(
                "[yellow]âš ï¸ Ollama ì„œë¹„ìŠ¤ê°€ ì‹¤í–‰ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.[/yellow]",
                border_style="yellow",
                padding=(1, 2)
            )
            self.console.print(warning_panel)
            return False

        success_panel = Panel(
            "[green]âœ“ Ollama ì„œë¹„ìŠ¤ê°€ ì‹¤í–‰ ì¤‘ì…ë‹ˆë‹¤.[/green]",
            border_style="green",
            padding=(0, 1)
        )
        self.console.print(success_panel)

        models_panel = Panel(
            "[bold bright_magenta]ğŸ“¦ ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸ì„ í™•ì¸í•©ë‹ˆë‹¤...[/bold bright_magenta]",
            border_style="magenta",
            padding=(1, 2)
        )
        self.console.print(models_panel)

        models: list[str] = self.get_available_ollama_models()
        selected_model = select_from_menu(self.console, models, "ì‚¬ìš© ê°€ëŠ¥í•œ Ollama ëª¨ë¸", default_index=0)
        if selected_model is None:
            return False

        serve = self.run_ollama_serve()
        if not serve:
            error_panel = Panel(
                "[red]âŒ Ollama ì„œë¹„ìŠ¤ë¥¼ ì‹œì‘í•˜ëŠ”ë° ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.[/red]",
                border_style="red",
                padding=(1, 2)
            )
            self.console.print(error_panel)
            return

        load_model = self.load_model(selected_model)
        if not load_model:
            error_panel = Panel(
                "[red]âŒ ëª¨ë¸ì„ ë¡œë“œí•˜ëŠ”ë° ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.[/red]",
                border_style="red",
                padding=(1, 2)
            )
            self.console.print(error_panel)
            return False

        return True